{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb45zm_IHkFo",
        "outputId": "ba8d712c-10fa-4ae5-ffce-88190eaafe73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch Step: 0, Loss = 0.092102\n",
            "Accuracy of test: 0.923100\n",
            "---------------------------------------------\n",
            "Epoch Step: 5, Loss = 0.014397\n",
            "Accuracy of test: 0.952200\n",
            "---------------------------------------------\n",
            "Epoch Step: 10, Loss = 0.000000\n",
            "Accuracy of test: 0.955300\n",
            "---------------------------------------------\n",
            "Epoch Step: 15, Loss = 0.000629\n",
            "Accuracy of test: 0.961000\n",
            "---------------------------------------------\n",
            "Epoch Step: 20, Loss = 0.000000\n",
            "Accuracy of test: 0.956400\n",
            "---------------------------------------------\n",
            "Epoch Step: 25, Loss = 0.000308\n",
            "Accuracy of test: 0.922800\n",
            "---------------------------------------------\n",
            "Epoch Step: 30, Loss = 0.000334\n",
            "Accuracy of test: 0.902900\n",
            "---------------------------------------------\n",
            "Epoch Step: 35, Loss = 0.000977\n",
            "Accuracy of test: 0.867500\n",
            "---------------------------------------------\n",
            "Epoch Step: 40, Loss = 0.000868\n",
            "Accuracy of test: 0.871600\n",
            "---------------------------------------------\n",
            "Epoch Step: 45, Loss = 0.000763\n",
            "Accuracy of test: 0.860800\n",
            "---------------------------------------------\n",
            "Epoch Step: 50, Loss = 0.001172\n",
            "Accuracy of test: 0.826900\n",
            "---------------------------------------------\n",
            "Epoch Step: 55, Loss = 0.001587\n",
            "Accuracy of test: 0.741500\n",
            "---------------------------------------------\n",
            "Epoch Step: 60, Loss = 0.001172\n",
            "Accuracy of test: 0.794500\n",
            "---------------------------------------------\n",
            "Epoch Step: 65, Loss = 0.001677\n",
            "Accuracy of test: 0.708000\n",
            "---------------------------------------------\n",
            "Epoch Step: 70, Loss = 0.000965\n",
            "Accuracy of test: 0.758300\n",
            "---------------------------------------------\n",
            "Epoch Step: 75, Loss = 0.001322\n",
            "Accuracy of test: 0.670100\n",
            "---------------------------------------------\n",
            "Epoch Step: 80, Loss = 0.002076\n",
            "Accuracy of test: 0.655500\n",
            "---------------------------------------------\n",
            "Epoch Step: 85, Loss = 0.002512\n",
            "Accuracy of test: 0.537900\n",
            "---------------------------------------------\n",
            "Epoch Step: 90, Loss = 0.001642\n",
            "Accuracy of test: 0.664000\n",
            "---------------------------------------------\n",
            "Epoch Step: 95, Loss = 0.002046\n",
            "Accuracy of test: 0.663700\n",
            "---------------------------------------------\n",
            "Epoch Step: 100, Loss = 0.002767\n",
            "Accuracy of test: 0.539100\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "batch_size = 128\n",
        "nH1 = 256\n",
        "nH2 = 256\n",
        "nH3 = 256\n",
        "\n",
        "(x_train, y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
        "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1,784])\n",
        "x_train, x_test = x_train/255, x_test/255\n",
        "y_train, y_test = tf.one_hot(y_train, depth=10), tf.one_hot(y_test,depth=10)\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.shuffle(60000).batch(batch_size)\n",
        "\n",
        "class ANN(object):\n",
        "  def __init__(self):\n",
        "    self.W1 = tf.Variable(tf.random.normal(shape=[784, nH1]))\n",
        "    self.W2 = tf.Variable(tf.random.normal(shape=[nH1, nH2]))\n",
        "    self.W3 = tf.Variable(tf.random.normal(shape=[nH2, nH3]))\n",
        "    self.Wout = tf.Variable(tf.random.normal(shape=[nH3, 10]))\n",
        "\n",
        "    self.b1 = tf.Variable(tf.random.normal(shape=[nH1]))\n",
        "    self.b2 = tf.Variable(tf.random.normal(shape=[nH2]))\n",
        "    self.b3 = tf.Variable(tf.random.normal(shape=[nH3]))\n",
        "    self.bout = tf.Variable(tf.random.normal(shape=[10]))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    H1_out = tf.nn.relu(tf.matmul(x, self.W1) + self.b1)\n",
        "    H2_out = tf.nn.relu(tf.matmul(H1_out, self.W2) + self.b2)\n",
        "    H3_out = tf.nn.relu(tf.matmul(H2_out, self.W3) + self.b3)\n",
        "\n",
        "    out = tf.matmul(H3_out, self.Wout) + self.bout\n",
        "\n",
        "    return out\n",
        "\n",
        "ANN_model = ANN()\n",
        "\n",
        "optimizer = tf.optimizers.Adam(0.01)\n",
        "\n",
        "@tf.function\n",
        "def accuracy(x, y):\n",
        "  correct = tf.equal(tf.argmax(x, 1), tf.argmax(y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(x)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y))\n",
        "\n",
        "  gradients = tape.gradient(loss, vars(model).values())\n",
        "  optimizer.apply_gradients(zip(gradients, vars(model).values()))  #weight update\n",
        "\n",
        "for epoch in range(101):\n",
        "  avg_loss = 0\n",
        "  tot_batch = int(x_train.shape[0] / batch_size)\n",
        "\n",
        "  for batch_x, batch_y in train_data:\n",
        "    train_step(ANN_model, batch_x, batch_y)\n",
        "    current_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=ANN_model(batch_x), labels=batch_y))\n",
        "    #current_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=ANN_model(batch_x), labels=batch_y))\n",
        "  avg_loss = avg_loss + current_loss/tot_batch\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    print(\"Epoch Step: %d, Loss = %f\" % ((epoch), avg_loss))\n",
        "    print(\"Accuracy of test: %f\"% accuracy(ANN_model(x_test), y_test))\n",
        "    print(\"---------------------------------------------\")\n",
        "\n"
      ]
    }
  ]
}
