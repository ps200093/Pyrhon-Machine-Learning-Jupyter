{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_JWV18HdtvX",
        "outputId": "6114d089-0796-41ad-c2d5-2ab0446e8192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "\n",
            "Epoch :  0\n",
            "Iteration :  300\n",
            "Loss :  0.00027381294\n",
            "Accuracy of test =  0.9698\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  1\n",
            "Iteration :  300\n",
            "Loss :  0.0003316561\n",
            "Accuracy of test =  0.9712\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  2\n",
            "Iteration :  300\n",
            "Loss :  0.0006268171\n",
            "Accuracy of test =  0.9625\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  3\n",
            "Iteration :  300\n",
            "Loss :  0.00077686075\n",
            "Accuracy of test =  0.972\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  4\n",
            "Iteration :  300\n",
            "Loss :  0.0008934253\n",
            "Accuracy of test =  0.9611\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  5\n",
            "Iteration :  300\n",
            "Loss :  0.0011007012\n",
            "Accuracy of test =  0.942\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  6\n",
            "Iteration :  300\n",
            "Loss :  0.0012112373\n",
            "Accuracy of test =  0.97\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  7\n",
            "Iteration :  300\n",
            "Loss :  0.001354851\n",
            "Accuracy of test =  0.9664\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  8\n",
            "Iteration :  300\n",
            "Loss :  0.0013871633\n",
            "Accuracy of test =  0.9673\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  9\n",
            "Iteration :  300\n",
            "Loss :  0.0014770555\n",
            "Accuracy of test =  0.9735\n",
            "------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "\n",
        "batch_size = 128\n",
        "conv1_filters = 32\n",
        "conv2_filters = 64\n",
        "fc1_units = 1024\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() # load MNIST data\n",
        "x_train,x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "x_train,x_test = x_train / 255, x_test / 255\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
        "\n",
        "class CNN(Model):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()  #입력 데이터 크기 28*28*1\n",
        "    self.conv1 = layers.Conv2D(32,kernel_size=3,activation=tf.nn.relu) # 채널 크기 ((28 - 3) / 1(stride)) + 1 = 26*26*32\n",
        "    self.maxpool1 = layers.MaxPool2D(2, strides=2) # 채널 크기 ((26 - 2) / 2(stride)) + 1 = 13*13*32\n",
        "    self.conv2 = layers.Conv2D(64,kernel_size=3,activation=tf.nn.relu ) # 채널 크기 ((13 - 3) / 1(stride)) + 1 = 11*11*64\n",
        "    self.maxpool2 = layers.MaxPool2D(2, strides=2) # 채널 크기 ((11 - 2) / 2(stride)) + 1 = 5.5(소수점은 버림) = 5*5*64\n",
        "    self.flatten = layers.Flatten()\n",
        "    self.fc1 = layers.Dense(1024) # 노드 개수 = 1024\n",
        "    self.out = layers.Dense(10) # 출력 노드 = 10\n",
        "\n",
        "  def call(self,x):\n",
        "    x = tf.reshape(x,[-1, 28, 28, 1])\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "CNN_model = CNN()\n",
        "\n",
        "optimizer = tf.optimizers.Adam(0.01)\n",
        "\n",
        "@tf.function\n",
        "def cross_entropy_loss(x, y):\n",
        "  y = tf.cast(y, tf.int64)\n",
        "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=x)\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "@tf.function\n",
        "def accuracy(x, y):\n",
        "  correct = tf.equal(tf.argmax(x,1), tf.cast(y, tf.int64))\n",
        "  return tf.reduce_mean(tf.cast(correct, tf.float32), axis = -1)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as g:\n",
        "    y_pred = CNN_model(x)\n",
        "    loss = cross_entropy_loss(y_pred, y)\n",
        "    #loss = nn.CrossEntropyLoss(y_pred, y)\n",
        "    trainable_variables = CNN_model.trainable_variables\n",
        "  gradients = g.gradient(loss, trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "avg_loss = 0\n",
        "tot_batch = int(x_train.shape[0]/batch_size)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for iter, (batch_x, batch_y) in enumerate(train_data.take(300), 1):\n",
        "    train_step(batch_x, batch_y)\n",
        "    current_loss = cross_entropy_loss(CNN_model(batch_x),batch_y)\n",
        "    #current_loss = nn.CrossEntropyLoss(CNN_model(batch_x),batch_y)\n",
        "\n",
        "  avg_loss = avg_loss + current_loss/tot_batch\n",
        "  if iter % 10 == 0:\n",
        "    print(\"\\nEpoch : \", epoch)\n",
        "    print(\"Iteration : \", iter)\n",
        "    print(\"Loss : \", avg_loss.numpy())\n",
        "    print(\"Accuracy of test = \", accuracy(CNN_model(x_test), y_test).numpy())\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "    #print(\"Epoch: %d, Iteration: %d, Loss = %f, Accuracy of test: %f\"% (epoch, iter, avg_loss, accuracy(CNN_model(x_test), y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "\n",
        "batch_size = 128\n",
        "conv1_filters = 32\n",
        "conv2_filters = 64\n",
        "fc1_units = 1024\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() # load MNIST data\n",
        "x_train,x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "x_train,x_test = x_train / 255, x_test / 255\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
        "\n",
        "class CNN(Model):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()  #입력 데이터 크기 28*28*1\n",
        "    self.conv1 = layers.Conv2D(32,kernel_size=3,activation=tf.nn.relu) # 채널 크기 ((28 - 3) / 1(stride)) + 1 = 26*26*32\n",
        "    self.maxpool1 = layers.MaxPool2D(2, strides=2) # 채널 크기 ((26 - 2) / 2(stride)) + 1 = 13*13*32\n",
        "    self.conv2 = layers.Conv2D(64,kernel_size=3,activation=tf.nn.relu ) # 채널 크기 ((13 - 3) / 1(stride)) + 1 = 11*11*64\n",
        "    self.maxpool2 = layers.MaxPool2D(2, strides=2) # 채널 크기 ((11 - 2) / 2(stride)) + 1 = 5.5(소수점은 버림) = 5*5*64\n",
        "    self.flatten = layers.Flatten()\n",
        "    self.fc1 = layers.Dense(1024) # 노드 개수 = 1024\n",
        "    self.out = layers.Dense(10) # 출력 노드 = 10\n",
        "\n",
        "  def call(self,x):\n",
        "    x = tf.reshape(x,[-1, 28, 28, 1])\n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "CNN_model = CNN()\n",
        "\n",
        "optimizer = tf.optimizers.Adam(0.01)\n",
        "\n",
        "@tf.function\n",
        "def cross_entropy_loss(x, y):\n",
        "  y = tf.cast(y, tf.int64)\n",
        "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=x)\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "@tf.function\n",
        "def accuracy(x, y):\n",
        "  correct = tf.equal(tf.argmax(x,1), tf.cast(y, tf.int64))\n",
        "  return tf.reduce_mean(tf.cast(correct, tf.float32), axis = -1)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as g:\n",
        "    y_pred = CNN_model(x)\n",
        "    loss = cross_entropy_loss(y_pred, y)\n",
        "    #loss = nn.CrossEntropyLoss(y_pred, y)\n",
        "    trainable_variables = CNN_model.trainable_variables\n",
        "  gradients = g.gradient(loss, trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "\n",
        "avg_loss = 0\n",
        "tot_batch = int(x_train.shape[0]/batch_size)\n",
        "epoch_loss = []\n",
        "acc_loss = 0\n",
        "\n",
        "for epoch in range(10):\n",
        "  avg_loss = 0\n",
        "  tot_batch = int(x_train.shape[0]/batch_size)\n",
        "  for iter, (batch_x, batch_y) in enumerate(train_data.take(100), 1):\n",
        "    train_step(batch_x, batch_y)\n",
        "    current_loss = cross_entropy_loss(CNN_model(batch_x),batch_y)\n",
        "    #current_loss = nn.CrossEntropyLoss(CNN_model(batch_x),batch_y)\n",
        "    #acc_loss += current_loss\n",
        "  #epoch_loss.append(acc_loss / iter)\n",
        "\n",
        "  avg_loss = avg_loss + current_loss/tot_batch\n",
        "  if iter % 10 == 0:\n",
        "    print(\"\\nEpoch : \", epoch)\n",
        "    print(\"Iteration : \", iter)\n",
        "    print(\"Loss : \", avg_loss.numpy())\n",
        "    #print(\"epoch_Loss : \", epoch_loss)\n",
        "    print(\"Accuracy of test = \", accuracy(CNN_model(x_test), y_test).numpy())\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "    #print(\"Epoch: %d, Iteration: %d, Loss = %f, Accuracy of test: %f\"% (epoch, iter, avg_loss, accuracy(CNN_model(x_test), y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIf5ecznPbuo",
        "outputId": "7aedd82c-fb0e-4cb9-9625-10e5622f7638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch :  0\n",
            "Iteration :  100\n",
            "Loss :  0.00012820243\n",
            "Accuracy of test =  0.963\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  1\n",
            "Iteration :  100\n",
            "Loss :  9.349916e-05\n",
            "Accuracy of test =  0.9689\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  2\n",
            "Iteration :  100\n",
            "Loss :  4.3221182e-05\n",
            "Accuracy of test =  0.9686\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  3\n",
            "Iteration :  100\n",
            "Loss :  0.00019004833\n",
            "Accuracy of test =  0.9686\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  4\n",
            "Iteration :  100\n",
            "Loss :  0.0001548598\n",
            "Accuracy of test =  0.9654\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  5\n",
            "Iteration :  100\n",
            "Loss :  6.0744e-05\n",
            "Accuracy of test =  0.9652\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  6\n",
            "Iteration :  100\n",
            "Loss :  5.5950986e-05\n",
            "Accuracy of test =  0.9698\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  7\n",
            "Iteration :  100\n",
            "Loss :  0.00015661606\n",
            "Accuracy of test =  0.9696\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  8\n",
            "Iteration :  100\n",
            "Loss :  6.351573e-05\n",
            "Accuracy of test =  0.9741\n",
            "------------------------------------------------------------------\n",
            "\n",
            "Epoch :  9\n",
            "Iteration :  100\n",
            "Loss :  0.00020843782\n",
            "Accuracy of test =  0.966\n",
            "------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}
