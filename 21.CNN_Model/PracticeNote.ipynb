{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XNjbuSsiOOnk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "\n",
        "class CNN(Model):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.con1 = layers.Conv2D(32, kernel_size = 3, activation = tf.nn.relu)\n",
        "    self.maxpl1 = layers.MaxPool2D(2, strides = 2)\n",
        "    self.con2 = layers.Conv2D(64, kernel_size = 3, activation = tf.nn.relu)\n",
        "    self.maxpl2 = layers.MaxPool2D(2, strides = 2)\n",
        "    self.ftlayer = layers.Flatten()\n",
        "    self.fclayer1 = layers.Dense(1024)\n",
        "    self.outlayer = layers.Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = tf.reshape(x, [-1, 28, 28, 1])\n",
        "    x = self.con1(x)\n",
        "    x = self.maxpl2(x)\n",
        "    x = self.con2(x)\n",
        "    x = self.maxpl2(x)\n",
        "    x = self.ftlayer(x)\n",
        "    x = self.fclayer1(x)\n",
        "    x = self.outlayer(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##BackPropagation\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "x_data = np.array([[0.1, 0.2]],dtype = np.float32)\n",
        "y_data = np.array([[0.4, 0.6]],dtype = np.float32)\n",
        "\n",
        "w1 = 0.3\n",
        "w2 = 0.25\n",
        "w3 = 0.4\n",
        "w4 = 0.35\n",
        "\n",
        "w5 = 0.45\n",
        "w6 = 0.4\n",
        "w7 = 0.7\n",
        "w8 = 0.6\n",
        "\n",
        "W1 = tf.Variable(tf.constant([[w1, w2], [w3, w4]], dtype = tf.float32))\n",
        "W2 = tf.Variable(tf.constant([[w5, w6], [w7, w8]], dtype = tf.float32))\n",
        "#W3 = tf.Variable(tf.constant([[w9, w10], [w11, w12]], dtype = tf.float32))\n",
        "\n",
        "learning_rate = 0.5\n",
        "\n",
        "cost_val = []\n",
        "\n",
        "def backPropagation():\n",
        "  with tf.GradientTape() as tape:\n",
        "    t1_layer = tf.matmul(x_data, W1)\n",
        "    z1_layer = tf.sigmoid(t1_layer)\n",
        "\n",
        "    t2_layer = tf.matmul(z1_layer, W2)\n",
        "    z2_layer = tf.sigmoid(t2_layer)\n",
        "\n",
        "    error = tf.reduce_mean(np.square(y_data - z2_layer))\n",
        "\n",
        "    gradients = tape.gradient(error,[W1, W2])\n",
        "    tf.optimizers.SGD(learning_rate).apply_gradients(zip(gradients, [W1, W2]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DuYncMp-HgWm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def accuracy(x, y):\n",
        "  correct = tf.equal(tf.argmax(x,1), tf.cast(y, tf.int64))\n",
        "  return tf.reduce_mean(tf.cast(correct, tf.float32), axis = -1)\n",
        "\n",
        "\n",
        "correct = tf.equal(tf.argmax(x_data,1), tf.cast(y_data, tf.int64))\n"
      ],
      "metadata": {
        "id": "4FKRljXpIX2_"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}